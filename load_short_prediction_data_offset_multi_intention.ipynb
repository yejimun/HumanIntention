{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ed7b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isdir, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import rosbag\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import pdb\n",
    "import math\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from os import makedirs\n",
    "import time\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8046e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath = 'short_prediction_multi_intention_data.pt'\n",
    "dataset = torch.load(dataset_filepath)\n",
    "\n",
    "xobs_train, xpred_train, yintention_train, xobs_test, xpred_test, yintention_test = \\\n",
    "dataset[\"xobs_train\"], dataset[\"xpred_train\"], dataset[\"yintention_train\"], dataset[\"xobs_test\"], \\\n",
    "dataset[\"xpred_test\"], dataset[\"yintention_test\"]\n",
    "obs_seq_len, pred_seq_len = dataset[\"obs_seq_len\"], dataset[\"pred_seq_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d5ed849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = torch.cat([xobs_train, xpred_train], dim=1) # (798, 10, 2)\n",
    "# x_test = torch.cat([xobs_test, xpred_test], dim=1) # (178, 10, 2)\n",
    "# x_train = x_train[:,1:] - x_train[:,:-1] # (N, 9, 2)\n",
    "# x_test = x_test[:,1:] - x_test[:,:-1] # (N, 9, 2)\n",
    "# x_train = torch.cat([torch.zeros(x_train.shape[0], 1, 2), x_train], dim=1) # (N, 10, 2)\n",
    "# x_test = torch.cat([torch.zeros(x_test.shape[0], 1, 2), x_test], dim=1) # (N, 10, 2)\n",
    "# xobs_train, xpred_train = x_train[:,:obs_seq_len], x_train[:,obs_seq_len:]\n",
    "# xobs_test, xpred_test = x_test[:,:obs_seq_len], x_test[:,obs_seq_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a0551e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size=32,\n",
    "        obs_seq_len=4,\n",
    "        pred_seq_len=6,\n",
    "        embedding_size=32,\n",
    "        hidden_size=32,\n",
    "        num_layers=1,\n",
    "        dropout=0.,\n",
    "        lr=1e-3,\n",
    "        num_epochs=300,\n",
    "        clip_grad=10.,\n",
    "        device=\"cuda:0\",\n",
    "        checkpoint_dir=\"checkpoints_multi_intention\",\n",
    "        ):\n",
    "        self.batch_size = batch_size\n",
    "        self.obs_seq_len = obs_seq_len\n",
    "        self.pred_seq_len = pred_seq_len\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.clip_grad = clip_grad\n",
    "        self.device = device\n",
    "        self.checkpoint_dir=checkpoint_dir\n",
    "\n",
    "args = Arguments(\n",
    "    obs_seq_len=obs_seq_len,\n",
    "    pred_seq_len=pred_seq_len,\n",
    "    lr=5e-3,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5395b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoriesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        xobs,\n",
    "        xpred,\n",
    "        yintention,\n",
    "        obs_seq_len=4,\n",
    "        pred_seq_len=6,\n",
    "        ):\n",
    "        super(TrajectoriesDataset, self).__init__()\n",
    "        assert xobs.shape[0]==xpred.shape[0]==yintention.shape[0]\n",
    "        assert xobs.shape[1]==obs_seq_len and xpred.shape[1]==pred_seq_len\n",
    "        self.obs_seq_len = obs_seq_len\n",
    "        self.pred_seq_len = pred_seq_len\n",
    "        self.seq_len = self.obs_seq_len + self.pred_seq_len\n",
    "        self.xobs = xobs\n",
    "        self.xpred = xpred\n",
    "        self.yintention = yintention\n",
    "        self.num_seq = self.xobs.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_seq\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        out = [\n",
    "            self.xobs[index][:,:3], # remove dt\n",
    "            self.xpred[index][:,:3], # remove dt\n",
    "            self.yintention[index],\n",
    "        ]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fad41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "for train_index, validation_index in kf.split(xobs_train):\n",
    "    xobs_train_k, xobs_val_k = xobs_train[train_index], xobs_train[validation_index]\n",
    "    xpred_train_k, xpred_val_k = xpred_train[train_index], xpred_train[validation_index] \n",
    "    yintention_train_k, yintention_val_k = yintention_train[train_index], yintention_train[validation_index]\n",
    "    dataset_train = TrajectoriesDataset(\n",
    "        xobs_train_k,\n",
    "        xpred_train_k,\n",
    "        yintention_train_k,\n",
    "        obs_seq_len=obs_seq_len,\n",
    "        pred_seq_len=pred_seq_len,\n",
    "    )\n",
    "    dataset_val = TrajectoriesDataset(\n",
    "        xobs_val_k,\n",
    "        xpred_val_k,\n",
    "        yintention_val_k,\n",
    "        obs_seq_len=obs_seq_len,\n",
    "        pred_seq_len=pred_seq_len,\n",
    "    )\n",
    "    loader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,  \n",
    "    )\n",
    "    loader_val = DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,  \n",
    "    )\n",
    "    break\n",
    "\n",
    "    \n",
    "dataset_test = TrajectoriesDataset(\n",
    "    xobs_test,\n",
    "    xpred_test,\n",
    "    yintention_test,\n",
    "    obs_seq_len=obs_seq_len,\n",
    "    pred_seq_len=pred_seq_len,\n",
    ")\n",
    "\n",
    "loader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0b963e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentionLstm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size=32,\n",
    "        hidden_size=32,\n",
    "        num_layers=1,\n",
    "        dropout=0.,\n",
    "        bidirectional=False,\n",
    "        obs_seq_len=4,\n",
    "        pred_seq_len=6,\n",
    "    ):\n",
    "        super(IntentionLstm, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=2*embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "            )\n",
    "        self.spatial_embedding = nn.Linear(3, embedding_size)\n",
    "        self.intention_embedding = nn.Linear(1, embedding_size)\n",
    "        if bidirectional:\n",
    "            self.directions = 2\n",
    "        else:\n",
    "            self.directions = 1\n",
    "        self.hidden_to_pos = nn.Linear(self.directions*num_layers*hidden_size, 3)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.obs_seq_len = obs_seq_len\n",
    "        self.pred_seq_len = pred_seq_len\n",
    "    \n",
    "    def forward(self, b_xobs, b_yintention, device=\"cuda:0\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Forward function.\n",
    "        inputs:\n",
    "            - b_xobs: batch of observation. (batch, obs_seq_len, 3)\n",
    "            - b_yintention: batch of intention. (batch, 1)\n",
    "        outputs:\n",
    "            - b_xpred: (batch, pred_seq_len, 3)\n",
    "            \n",
    "        \"\"\"\n",
    "        batch_size, _, _ = b_xobs.shape\n",
    "        b_xobs_offset = b_xobs[:,1:] - b_xobs[:,:-1] # (N, obs_seq_len-1,2)\n",
    "        b_xobs_offset_embedding = self.spatial_embedding(b_xobs_offset) # (batch, obs_seq_len, embedding_size)\n",
    "        b_yintention_embedding = self.intention_embedding(b_yintention.unsqueeze(-1)) # (batch, 1, embedding_size)\n",
    "        b_obs_embedding = torch.cat((b_xobs_offset_embedding, \\\n",
    "                                   b_yintention_embedding*torch.ones(batch_size, self.obs_seq_len-1, self.embedding_size).to(device)), \\\n",
    "                                   dim=2) # (batch, obs_seq_len-1, 2*embedding_size)\n",
    "        _, (ht, ct) = self.lstm(b_obs_embedding) # (Dâˆ—num_layers, batch, hidden_size)\n",
    "        b_xpred_tt = b_xobs[:,-1:] # (batch, 1, 2)\n",
    "        b_xpred = []\n",
    "        b_xpred_tt_offset = self.hidden_to_pos(ht.permute(1,0,2).reshape(batch_size,1,-1)) # (batch, 1, 2)\n",
    "        b_xpred_tt = b_xpred_tt + b_xpred_tt_offset\n",
    "        b_xpred.append(b_xpred_tt)\n",
    "        for tt in range(1, self.pred_seq_len):\n",
    "            b_pred_tt_offset_embedding = torch.cat((self.spatial_embedding(b_xpred_tt_offset), b_yintention_embedding), dim=2)\n",
    "            _, (ht, ct) = self.lstm(b_pred_tt_offset_embedding, (ht, ct))\n",
    "            b_xpred_tt_offset = self.hidden_to_pos(ht.permute(1,0,2).reshape(batch_size,1,-1)) # (batch, 1, 2)\n",
    "            b_xpred_tt = b_xpred_tt + b_xpred_tt_offset\n",
    "            b_xpred.append(b_xpred_tt)\n",
    "        b_xpred = torch.cat(b_xpred, dim=1)\n",
    "        return b_xpred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1b63181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader_train, loader_val):\n",
    "    model = IntentionLstm(\n",
    "        embedding_size=args.embedding_size,\n",
    "        hidden_size=args.hidden_size,\n",
    "        num_layers=args.num_layers,\n",
    "        dropout=args.dropout,\n",
    "        bidirectional=False,\n",
    "        obs_seq_len=args.obs_seq_len,\n",
    "        pred_seq_len=args.pred_seq_len,\n",
    "    ).to(args.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    now = datetime.now()\n",
    "    curr_checkpoint_dir = join(args.checkpoint_dir, now.strftime(\"%y%m%d_%H%M%S\"))\n",
    "    if not isdir(curr_checkpoint_dir):\n",
    "        makedirs(curr_checkpoint_dir)\n",
    "    with open(join(curr_checkpoint_dir, 'args.pickle'), 'wb') as f:\n",
    "        pickle.dump(args, f)\n",
    "    print('EPOCHS: ', args.num_epochs)\n",
    "    train_loss_task, train_aoe_task, train_foe_task = [], [], []\n",
    "    val_loss_task, val_aoe_task, val_foe_task = [], [], []\n",
    "    \n",
    "    for epoch in range(1, args.num_epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss_epoch, train_aoe_epoch, train_foe_epoch = [], [], []\n",
    "        for batch_idx, batch in enumerate(loader_train):\n",
    "            batch = [b.to(args.device) for b in batch]\n",
    "            b_xobs, b_xpred_gt, b_yintention = batch\n",
    "            optimizer.zero_grad()\n",
    "            b_xpred = model(b_xobs, b_yintention, device=args.device) # (batch, pred_seq_len, 2)\n",
    "            loss = ((b_xpred-b_xpred_gt)**2.).mean()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
    "            optimizer.step()\n",
    "            offset_error = (((b_xpred-b_xpred_gt)**2.).sum(2))**0.5 # (batch, pred_seq_len)\n",
    "            aoe, foe = offset_error.mean(-1).mean(), offset_error[-1].mean()\n",
    "            train_loss_epoch.append(loss.detach().to('cpu').item())\n",
    "            train_aoe_epoch.append(aoe.detach().to('cpu').item())\n",
    "            train_foe_epoch.append(foe.detach().to('cpu').item())\n",
    "        train_loss_epoch = sum(train_loss_epoch)/len(train_loss_epoch)\n",
    "        train_aoe_epoch = sum(train_aoe_epoch)/len(train_aoe_epoch)\n",
    "        train_foe_epoch = sum(train_foe_epoch)/len(train_foe_epoch)\n",
    "        val_loss_epoch, val_aoe_epoch, val_foe_epoch = inference(args, loader_val, model)\n",
    "        if epoch % 10 == 0:\n",
    "#             print('Epoch: {0} | train loss: {1:.2f} | val loss: {2:.2f} | train aoe: {3:.2f} | val aoe: {4:.2f} | train foe: {5:.2f} | val foe: {6:.2f} | period: {7:.2f} sec'\\\n",
    "#                 .format(epoch, train_loss_epoch, val_loss_epoch,\\\n",
    "#                 train_aoe_epoch, val_aoe_epoch,\\\n",
    "#                 train_foe_epoch, val_foe_epoch,\\\n",
    "#                 time.time()-epoch_start_time)) \n",
    "            print('Epoch: {0} | train aoe: {1:.2f} | val aoe: {2:.2f} | train foe: {3:.2f} | val foe: {4:.2f} | period: {5:.2f} sec'\\\n",
    "                .format(epoch, \\\n",
    "                train_aoe_epoch*1000, val_aoe_epoch*1000,\\\n",
    "                train_foe_epoch*1000, val_foe_epoch*1000,\\\n",
    "                time.time()-epoch_start_time)) \n",
    "            model_filename = join(curr_checkpoint_dir, 'epoch_'+str(epoch)+'.pt')\n",
    "            torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': train_loss_epoch,\n",
    "                    'val_loss': val_loss_epoch,\n",
    "                    'train_aoe': train_aoe_epoch,\n",
    "                    'val_aoe': val_aoe_epoch, \n",
    "                    'train_foe': train_foe_epoch,\n",
    "                    'val_foe': val_foe_epoch,   \n",
    "                    }, model_filename)\n",
    "            # print('epoch_'+str(epoch)+'.pt is saved.')\n",
    "        train_loss_task.append(train_loss_epoch)\n",
    "        train_aoe_task.append(train_aoe_epoch)\n",
    "        train_foe_task.append(train_foe_epoch)\n",
    "        val_loss_task.append(val_loss_epoch)\n",
    "        val_aoe_task.append(val_aoe_epoch)\n",
    "        val_foe_task.append(val_foe_epoch)\n",
    "    hist = {}\n",
    "    hist['train_loss'], hist['val_loss'] = train_loss_task, val_loss_task\n",
    "    hist['train_aoe'], hist['val_aoe'] = train_aoe_task, val_aoe_task\n",
    "    hist['train_foe'], hist['val_foe'] = train_foe_task, val_foe_task\n",
    "    with open(join(curr_checkpoint_dir, 'train_hist.pickle'), 'wb') as f:\n",
    "        pickle.dump(hist, f)\n",
    "        print(join(curr_checkpoint_dir, 'train_hist.pickle')+' is saved.')\n",
    "    return\n",
    "\n",
    "\n",
    "def inference(args, loader, model, reverse_intention=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_epoch, aoe_epoch, foe_epoch = [], [], []\n",
    "        for batch_idx, batch in enumerate(loader):\n",
    "            batch = [b.to(args.device) for b in batch]\n",
    "            b_xobs, b_xpred_gt, b_yintention = batch\n",
    "            if reverse_intention:\n",
    "                b_yintention = 1.-b_yintention\n",
    "            b_xpred = model(b_xobs, b_yintention, device=args.device) # (batch, pred_seq_len, 2)\n",
    "            loss = ((b_xpred-b_xpred_gt)**2.).mean()\n",
    "            offset_error = (((b_xpred-b_xpred_gt)**2.).sum(2))**0.5 # (batch, pred_seq_len)\n",
    "            aoe, foe = offset_error.mean(-1).mean(), offset_error[-1].mean()\n",
    "            loss_epoch.append(loss.detach().to('cpu').item())\n",
    "            aoe_epoch.append(aoe.detach().to('cpu').item())\n",
    "            foe_epoch.append(foe.detach().to('cpu').item())\n",
    "        loss_epoch = sum(loss_epoch)/len(loss_epoch)\n",
    "        aoe_epoch = sum(aoe_epoch)/len(aoe_epoch)\n",
    "        foe_epoch = sum(foe_epoch)/len(foe_epoch)\n",
    "    return loss_epoch, aoe_epoch, foe_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0e49074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  300\n",
      "Epoch: 10 | train aoe: 23.55 | val aoe: 19.41 | train foe: 28.88 | val foe: 14.32 | period: 0.64 sec\n",
      "Epoch: 20 | train aoe: 24.72 | val aoe: 19.59 | train foe: 22.54 | val foe: 15.56 | period: 0.65 sec\n",
      "Epoch: 30 | train aoe: 24.36 | val aoe: 21.95 | train foe: 18.77 | val foe: 19.68 | period: 0.66 sec\n",
      "Epoch: 40 | train aoe: 24.11 | val aoe: 25.62 | train foe: 20.19 | val foe: 23.23 | period: 0.65 sec\n",
      "Epoch: 50 | train aoe: 24.83 | val aoe: 18.61 | train foe: 35.20 | val foe: 14.59 | period: 0.67 sec\n",
      "Epoch: 60 | train aoe: 24.33 | val aoe: 30.40 | train foe: 26.07 | val foe: 30.63 | period: 0.81 sec\n",
      "Epoch: 70 | train aoe: 24.24 | val aoe: 20.45 | train foe: 27.63 | val foe: 18.14 | period: 0.78 sec\n",
      "Epoch: 80 | train aoe: 24.33 | val aoe: 18.76 | train foe: 27.20 | val foe: 13.78 | period: 0.81 sec\n",
      "Epoch: 90 | train aoe: 23.25 | val aoe: 22.99 | train foe: 20.81 | val foe: 20.65 | period: 0.84 sec\n",
      "Epoch: 100 | train aoe: 23.63 | val aoe: 21.18 | train foe: 28.36 | val foe: 19.93 | period: 0.84 sec\n",
      "Epoch: 110 | train aoe: 23.26 | val aoe: 22.70 | train foe: 20.83 | val foe: 20.73 | period: 0.80 sec\n",
      "Epoch: 120 | train aoe: 22.79 | val aoe: 20.41 | train foe: 17.55 | val foe: 16.17 | period: 0.81 sec\n",
      "Epoch: 130 | train aoe: 22.69 | val aoe: 18.66 | train foe: 22.37 | val foe: 16.75 | period: 0.95 sec\n",
      "Epoch: 140 | train aoe: 21.49 | val aoe: 27.59 | train foe: 20.60 | val foe: 29.19 | period: 0.90 sec\n",
      "Epoch: 150 | train aoe: 19.71 | val aoe: 16.51 | train foe: 16.72 | val foe: 16.93 | period: 0.80 sec\n",
      "Epoch: 160 | train aoe: 18.99 | val aoe: 15.65 | train foe: 21.37 | val foe: 16.41 | period: 0.89 sec\n",
      "Epoch: 170 | train aoe: 19.04 | val aoe: 31.59 | train foe: 14.59 | val foe: 36.77 | period: 0.78 sec\n",
      "Epoch: 180 | train aoe: 18.40 | val aoe: 18.17 | train foe: 18.07 | val foe: 20.12 | period: 0.81 sec\n",
      "Epoch: 190 | train aoe: 17.51 | val aoe: 15.23 | train foe: 15.37 | val foe: 16.03 | period: 0.88 sec\n",
      "Epoch: 200 | train aoe: 17.33 | val aoe: 18.95 | train foe: 14.16 | val foe: 21.79 | period: 0.87 sec\n",
      "Epoch: 210 | train aoe: 16.81 | val aoe: 14.05 | train foe: 19.65 | val foe: 12.83 | period: 0.68 sec\n",
      "Epoch: 220 | train aoe: 17.22 | val aoe: 15.08 | train foe: 16.39 | val foe: 14.14 | period: 0.71 sec\n",
      "Epoch: 230 | train aoe: 17.52 | val aoe: 14.00 | train foe: 20.13 | val foe: 14.76 | period: 0.69 sec\n",
      "Epoch: 240 | train aoe: 17.64 | val aoe: 15.37 | train foe: 16.49 | val foe: 16.88 | period: 0.73 sec\n",
      "Epoch: 250 | train aoe: 17.60 | val aoe: 17.47 | train foe: 16.84 | val foe: 17.30 | period: 0.64 sec\n",
      "Epoch: 260 | train aoe: 17.17 | val aoe: 16.72 | train foe: 13.67 | val foe: 12.84 | period: 0.67 sec\n",
      "Epoch: 270 | train aoe: 17.14 | val aoe: 16.12 | train foe: 16.56 | val foe: 15.94 | period: 0.70 sec\n",
      "Epoch: 280 | train aoe: 18.69 | val aoe: 16.91 | train foe: 14.54 | val foe: 19.53 | period: 0.69 sec\n",
      "Epoch: 290 | train aoe: 17.02 | val aoe: 19.18 | train foe: 15.55 | val foe: 21.93 | period: 0.59 sec\n",
      "Epoch: 300 | train aoe: 17.24 | val aoe: 18.83 | train foe: 12.88 | val foe: 21.33 | period: 0.53 sec\n",
      "checkpoints_multi_intention/211102_005828/train_hist.pickle is saved.\n"
     ]
    }
   ],
   "source": [
    "train(args, loader_train, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4ef5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test, name_checkpoint, visualize=True):\n",
    "    curr_checkpoint_dir = join(args.checkpoint_dir, name_checkpoint)\n",
    "    if not isdir(curr_checkpoint_dir):\n",
    "        raise RuntimeError(\"Checkpoint \"+name_checkpoint+\" does not exist.\")\n",
    "    with open(join(curr_checkpoint_dir, 'args.pickle'), 'rb') as f:\n",
    "        args_eval = pickle.load(f)\n",
    "    model = IntentionLstm(\n",
    "        embedding_size=args.embedding_size,\n",
    "        hidden_size=args.hidden_size,\n",
    "        num_layers=args.num_layers,\n",
    "        dropout=args.dropout,\n",
    "        bidirectional=False,\n",
    "        obs_seq_len=args.obs_seq_len,\n",
    "        pred_seq_len=args.pred_seq_len,\n",
    "    ).to(args.device)\n",
    "    model_checkpoint_filename = join(curr_checkpoint_dir, \"epoch_\"+str(args.num_epochs)+\".pt\")\n",
    "    model_checkpoint = torch.load(model_checkpoint_filename, map_location=device)\n",
    "    model.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "    print('Loaded configuration: ', model_checkpoint_filename)\n",
    "    start_time = time.time()\n",
    "    test_loss_epoch, test_aoe_epoch, test_foe_epoch = inference(args, loader_test, model)\n",
    "    end_time = time.time()\n",
    "    test_loss_epoch_ri, test_aoe_epoch_ri, test_foe_epoch_ri = inference(args, loader_test, model, reverse_intention=False)\n",
    "    print('Epoch: {0} | test aoe: {1:.2f} | test foe: {2:.2f} | period: {3:.2f} sec | not reversed'\\\n",
    "        .format(args.num_epochs, \\\n",
    "        test_aoe_epoch,\\\n",
    "        test_foe_epoch,\\\n",
    "        end_time-start_time))\n",
    "    print('Epoch: {0} | test aoe: {1:.2f} | test foe: {2:.2f} | period: {3:.2f} sec | reversed'\\\n",
    "        .format(args.num_epochs, \\\n",
    "        test_aoe_epoch_ri,\\\n",
    "        test_foe_epoch_ri,\\\n",
    "        end_time-start_time))\n",
    "    if visualize:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch_idx, batch in enumerate(loader_test):\n",
    "                batch = [b.to(args.device) for b in batch]\n",
    "                b_xobs, b_xpred_gt, b_yintention = batch\n",
    "                b_xpred = model(b_xobs, b_yintention, device=args.device) # (batch, pred_seq_len, 2)\n",
    "                b_xpred_reverse_intention = model(b_xobs, 1.-b_yintention, device=args.device) # (batch, pred_seq_len, 2)\n",
    "                b_x_gt = torch.cat([b_xobs, b_xpred_gt],dim=1).to(\"cpu\")\n",
    "                b_x_model = torch.cat([b_xobs, b_xpred],dim=1).to(\"cpu\")\n",
    "                b_x_model_2 = torch.cat([b_xobs, b_xpred_reverse_intention],dim=1).to(\"cpu\")\n",
    "#                 print(\"difference: \", ((b_xpred_reverse_intention-b_xpred)**2.).sum()**0.5)\n",
    "                for traj_idx in range(len(b_xobs[:3])):\n",
    "                    plt.figure()\n",
    "                    ax = plt.axes(projection='3d')\n",
    "                    ax.scatter3D(b_x_gt[traj_idx,:,0], b_x_gt[traj_idx,:,1],b_x_gt[traj_idx,:,2], 'o-', c='C0') # blue\n",
    "                    # print(b_x_model[traj_idx,:,0].shape, b_x_model[traj_idx,:,1].shape, b_x_model[traj_idx,:,2].shape)\n",
    "                    ax.scatter3D(b_x_model[traj_idx,:,0], b_x_model[traj_idx,:,1], b_x_model[traj_idx,:,2], 'o-', c='C1')#, markersize=10.) # orange\n",
    "                    # print(b_x_model_2[traj_idx,:,0].shape, b_x_model_2[traj_idx,:,1].shape, b_x_model_2[traj_idx,:,2].shape)\n",
    "                    ax.scatter3D(b_x_model_2[traj_idx,:,0], b_x_model_2[traj_idx,:,1], b_x_model_2[traj_idx,:,2], 'o-', c='C2') # green\n",
    "#                     print(b_x_model[traj_idx]-)\n",
    "                    # print(b_yintention[traj_idx])\n",
    "                    \n",
    "                    plt.show()\n",
    "                #break\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e409699",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Checkpoint 211101_231133 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8e24e82252f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mname_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"211101_231133\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-f22f05b1f09a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader_test, name_checkpoint, visualize)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcurr_checkpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_checkpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Checkpoint \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname_checkpoint\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_checkpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'args.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0margs_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Checkpoint 211101_231133 does not exist."
     ]
    }
   ],
   "source": [
    "name_checkpoint = \"211102_005828\"\n",
    "test(loader_test, name_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a818e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
