{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b113f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isdir, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import rosbag\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import pdb\n",
    "import math\n",
    "import torch\n",
    "from os.path import join\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28347f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hcalab/Desktop/MYJ/FIT/HumanIntention/Dataset/multi_intention_labeled.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f95b9e8f255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# data = pickle.load(f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hcalab/Desktop/MYJ/FIT/HumanIntention/Dataset/multi_intention_labeled.p'"
     ]
    }
   ],
   "source": [
    "\n",
    "pkg_path = '/home/hcalab/Desktop/MYJ/FIT/HumanIntention'\n",
    "dataset_filename = 'multi_intention_labeled.p'\n",
    "\n",
    "dataset_filepath = join(pkg_path, 'Dataset', dataset_filename)\n",
    "with open(dataset_filepath,'rb') as f:\n",
    "    # data = pickle.load(f)\n",
    "    \n",
    "    # for python3\n",
    "    u = pickle._Unpickler( f )\n",
    "    u.encoding = 'latin1'\n",
    "    data = u.load()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8102d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = [], [], [], []\n",
    "for intention in [0, 1, 2]:\n",
    "    intention_label = [intention for i in range(len(data[intention]))]\n",
    "    xtraini, xtesti, ytraini, ytesti = train_test_split(data[intention], intention_label, test_size=5, random_state=0)\n",
    "    xtrain += xtraini\n",
    "    ytrain += ytraini\n",
    "    xtest += xtesti\n",
    "    ytest += ytesti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c9f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_x, raw_y, obs_seq_len, pred_seq_len, skip=2):\n",
    "    seq_len = obs_seq_len+pred_seq_len\n",
    "    xobs, xpred, yintention = [], [], []\n",
    "    for x, y in zip(raw_x, raw_y):\n",
    "        n_seq = math.floor((len(x)-seq_len)/skip)+1\n",
    "        idx_range = range(0, n_seq*skip, skip)\n",
    "        for idx in idx_range:\n",
    "            seq_data = x[idx:idx+seq_len]# (seq_len, 2)\n",
    "            obs_seq_data, pred_seq_data = seq_data[:obs_seq_len], seq_data[obs_seq_len:]\n",
    "            xobs.append(obs_seq_data)\n",
    "            xpred.append(pred_seq_data)\n",
    "            yintention.append(y)\n",
    "            \n",
    "    xobs = torch.stack(xobs, dim=0) # (N, obs_seq_len, 2)\n",
    "    xpred = torch.stack(xpred, dim=0) # (N, pred_seq_len, 2)\n",
    "    yintention = torch.tensor(yintention).unsqueeze(1).type(torch.float) # (N, 1)\n",
    "    return xobs, xpred, yintention\n",
    "\n",
    "skip = 1\n",
    "obs_seq_len, pred_seq_len = 8, 12#4, 6\n",
    "\n",
    "xobs_train, xpred_train, yintention_train = process_data(xtrain, ytrain, obs_seq_len, pred_seq_len, skip=skip)\n",
    "xobs_test, xpred_test, yintention_test = process_data(xtest, ytest, obs_seq_len, pred_seq_len, skip=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e53caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"xobs_train\": xobs_train, \"xpred_train\": xpred_train, \"yintention_train\": yintention_train,\\\n",
    "            \"xobs_test\": xobs_test, \"xpred_test\": xpred_test, \"yintention_test\": yintention_test, \\\n",
    "            \"obs_seq_len\": obs_seq_len, \"pred_seq_len\": pred_seq_len, \"skip\": skip}, 'short_prediction_multi_intention_data_slow.pt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b469a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([386])\n",
      "tensor([520])\n",
      "tensor([351])\n"
     ]
    }
   ],
   "source": [
    "print(sum(yintention_train==0))\n",
    "print(sum(yintention_train==1))\n",
    "print(sum(yintention_train==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57bc02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8620,  0.2688,  0.1217,  0.0427],\n",
      "        [-0.8629,  0.2476,  0.1302,  0.0431],\n",
      "        [-0.8589,  0.2395,  0.1468,  0.0409],\n",
      "        [-0.8612,  0.2223,  0.1494,  0.0772]])\n",
      "tensor([64])\n",
      "tensor([110])\n",
      "tensor([78])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "for train_index, validation_index in kf.split(xobs_train):\n",
    "#     print(\"TRAIN:\", train_index, \"VAL:\", validation_index)\n",
    "    print(xobs_train[train_index][20])\n",
    "    print(sum(yintention_train[validation_index]==0))\n",
    "    print(sum(yintention_train[validation_index]==1))\n",
    "    print(sum(yintention_train[validation_index]==2))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30888f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "kf.get_n_splits()\n",
    "# print(kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd5b4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34551ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  3  4  6  7  8  9 10 12 13 14 15 17 18 20 21 22 23 24] VAL: [ 2  5 11 16 19]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 2]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 18 19 20 21] VAL: [14 17 22 23 24]\n",
      "TRAIN intentions: [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2]\n",
      "VAL intentions: [1 1 2 2 2]\n",
      "TRAIN: [ 0  2  3  4  5  7  9 11 12 14 15 16 17 18 19 20 21 22 23 24] VAL: [ 1  6  8 10 13]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 1]\n",
      "TRAIN: [ 0  1  2  3  5  6  8 10 11 12 13 14 15 16 17 19 21 22 23 24] VAL: [ 4  7  9 18 20]\n",
      "TRAIN intentions: [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "VAL intentions: [0 1 1 2 2]\n",
      "TRAIN: [ 1  2  4  5  6  7  8  9 10 11 13 14 16 17 18 19 20 22 23 24] VAL: [ 0  3 12 15 21]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "for train_index, validation_index in kf.split(xtrain, ytrain):\n",
    "    print(\"TRAIN:\", train_index, \"VAL:\", validation_index)\n",
    "    print('TRAIN intentions:', np.array(ytrain)[train_index])\n",
    "    print('VAL intentions:', np.array(ytrain)[validation_index])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9655b20497ebc56af2835b3068a63a68a9636051ead45439ace511dc06086c75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
