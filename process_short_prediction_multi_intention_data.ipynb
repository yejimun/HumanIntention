{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b113f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isdir, join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import rosbag\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import os\n",
    "import pdb\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e28347f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_path = '/home/hcalab/Desktop/MYJ/FIT/HumanIntention'\n",
    "dataset_filename = 'multi_intention_labeled.p'\n",
    "\n",
    "dataset_filepath = join(pkg_path, 'Dataset', dataset_filename)\n",
    "with open(dataset_filepath,'rb') as f:\n",
    "    # data = pickle.load(f)\n",
    "    \n",
    "    # for python3\n",
    "    u = pickle._Unpickler( f )\n",
    "    u.encoding = 'latin1'\n",
    "    data = u.load()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8102d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = [], [], [], []\n",
    "for intention in [0, 1, 2]:\n",
    "    intention_label = [intention for i in range(len(data[intention]))]\n",
    "    xtraini, xtesti, ytraini, ytesti = train_test_split(data[intention], intention_label, test_size=5, random_state=0)\n",
    "    xtrain += xtraini\n",
    "    ytrain += ytraini\n",
    "    xtest += xtesti\n",
    "    ytest += ytesti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11c9f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_x, raw_y, obs_seq_len, pred_seq_len, skip=2):\n",
    "    seq_len = obs_seq_len+pred_seq_len\n",
    "    xobs, xpred, yintention = [], [], []\n",
    "    for x, y in zip(raw_x, raw_y):\n",
    "        n_seq = math.floor((len(x)-seq_len)/skip)+1\n",
    "        idx_range = range(0, n_seq*skip, skip)\n",
    "        for idx in idx_range:\n",
    "            seq_data = x[idx:idx+seq_len]# (seq_len, 2)\n",
    "            obs_seq_data, pred_seq_data = seq_data[:obs_seq_len], seq_data[obs_seq_len:]\n",
    "            xobs.append(obs_seq_data)\n",
    "            xpred.append(pred_seq_data)\n",
    "            yintention.append(y)\n",
    "    xobs = torch.stack(xobs, dim=0) # (N, obs_seq_len, 2)\n",
    "    xpred = torch.stack(xpred, dim=0) # (N, pred_seq_len, 2)\n",
    "    yintention = torch.tensor(yintention).unsqueeze(1).type(torch.float) # (N, 1)\n",
    "    return xobs, xpred, yintention\n",
    "\n",
    "skip = 2\n",
    "obs_seq_len, pred_seq_len = 4, 6\n",
    "\n",
    "xobs_train, xpred_train, yintention_train = process_data(xtrain, ytrain, obs_seq_len, pred_seq_len, skip=2)\n",
    "xobs_test, xpred_test, yintention_test = process_data(xtest, ytest, obs_seq_len, pred_seq_len, skip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e53caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"xobs_train\": xobs_train, \"xpred_train\": xpred_train, \"yintention_train\": yintention_train,\\\n",
    "            \"xobs_test\": xobs_test, \"xpred_test\": xpred_test, \"yintention_test\": yintention_test, \\\n",
    "            \"obs_seq_len\": obs_seq_len, \"pred_seq_len\": pred_seq_len, \"skip\": skip}, 'short_prediction_multi_intention_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b469a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([386])\n",
      "tensor([520])\n",
      "tensor([351])\n"
     ]
    }
   ],
   "source": [
    "print(sum(yintention_train==0))\n",
    "print(sum(yintention_train==1))\n",
    "print(sum(yintention_train==2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57bc02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8620,  0.2688,  0.1217,  0.0427],\n",
      "        [-0.8629,  0.2476,  0.1302,  0.0431],\n",
      "        [-0.8589,  0.2395,  0.1468,  0.0409],\n",
      "        [-0.8612,  0.2223,  0.1494,  0.0772]])\n",
      "tensor([64])\n",
      "tensor([110])\n",
      "tensor([78])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "for train_index, validation_index in kf.split(xobs_train):\n",
    "#     print(\"TRAIN:\", train_index, \"VAL:\", validation_index)\n",
    "    print(xobs_train[train_index][20])\n",
    "    print(sum(yintention_train[validation_index]==0))\n",
    "    print(sum(yintention_train[validation_index]==1))\n",
    "    print(sum(yintention_train[validation_index]==2))\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc6b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30888f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "kf.get_n_splits()\n",
    "# print(kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd5b4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34551ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  3  4  6  7  8  9 10 12 13 14 15 17 18 20 21 22 23 24] VAL: [ 2  5 11 16 19]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 2]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 18 19 20 21] VAL: [14 17 22 23 24]\n",
      "TRAIN intentions: [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2]\n",
      "VAL intentions: [1 1 2 2 2]\n",
      "TRAIN: [ 0  2  3  4  5  7  9 11 12 14 15 16 17 18 19 20 21 22 23 24] VAL: [ 1  6  8 10 13]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 1]\n",
      "TRAIN: [ 0  1  2  3  5  6  8 10 11 12 13 14 15 16 17 19 21 22 23 24] VAL: [ 4  7  9 18 20]\n",
      "TRAIN intentions: [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\n",
      "VAL intentions: [0 1 1 2 2]\n",
      "TRAIN: [ 1  2  4  5  6  7  8  9 10 11 13 14 16 17 18 19 20 22 23 24] VAL: [ 0  3 12 15 21]\n",
      "TRAIN intentions: [0 0 0 0 0 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2]\n",
      "VAL intentions: [0 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "for train_index, validation_index in kf.split(xtrain, ytrain):\n",
    "    print(\"TRAIN:\", train_index, \"VAL:\", validation_index)\n",
    "    print('TRAIN intentions:', np.array(ytrain)[train_index])\n",
    "    print('VAL intentions:', np.array(ytrain)[validation_index])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9655b20497ebc56af2835b3068a63a68a9636051ead45439ace511dc06086c75"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('myenv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
